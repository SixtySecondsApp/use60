# Lead Qualification Scoring Frameworks: A Deep Comparison

A comprehensive reference for selecting and applying the right qualification framework based on deal complexity, ACV, and sales cycle length.

## Table of Contents

1. [Framework Overview](#framework-overview)
2. [BANT: Budget, Authority, Need, Timeline](#bant-budget-authority-need-timeline)
3. [MEDDICC: The Enterprise Standard](#meddicc-the-enterprise-standard)
4. [ANUM: Authority-First Qualification](#anum-authority-first-qualification)
5. [CHAMP: Challenges-Led Qualification](#champ-challenges-led-qualification)
6. [GPCTBA/C&I: The HubSpot Framework](#gpctbaci-the-hubspot-framework)
7. [The 5-Dimension Scoring Model](#the-5-dimension-scoring-model)
8. [Framework Selection Decision Tree](#framework-selection-decision-tree)
9. [Conversion Rate Data by Framework](#conversion-rate-data-by-framework)
10. [Scoring Rubric Worked Examples](#scoring-rubric-worked-examples)
11. [Framework Migration Guide](#framework-migration-guide)

---

## Framework Overview

Every qualification framework is a lens for the same underlying question: "Is this lead worth our time?" The difference is what each lens prioritizes and how deeply it probes.

| Framework | Primary Focus | Best For | Complexity | Time to Apply |
|-----------|--------------|----------|------------|---------------|
| BANT | Can they buy? | SMB/mid-market, transactional | Low | 2-5 minutes |
| MEDDICC | Will they buy from us? | Enterprise, complex deals | High | 15-30 minutes |
| ANUM | Who are we talking to? | Authority-gated orgs | Medium | 5-10 minutes |
| CHAMP | What problem do they have? | Solution selling, consultative | Medium | 5-10 minutes |
| GPCTBA/C&I | Do their goals align? | Inbound-heavy, advisory | High | 10-20 minutes |
| 5-Dimension | Rapid first-pass scoring | Any, especially data-sparse | Low-Medium | 3-7 minutes |

---

## BANT: Budget, Authority, Need, Timeline

### Origin and Philosophy
IBM created BANT in the 1960s as a simple filter for mainframe computer sales. Its elegance is its simplicity: four binary questions that, when all answered affirmatively, indicate a qualified lead. Sixty years later, it remains the most widely recognized framework in sales.

### Criteria Definitions

| Criterion | What You Are Assessing | Key Questions |
|-----------|----------------------|---------------|
| **Budget** | Does the prospect have allocated funds (or the ability to allocate funds) for a purchase in your price range? | "What budget have you set aside for this?" / "How does your org typically fund new tool purchases?" |
| **Authority** | Is this person the final decision-maker, or can they directly influence the decision? | "Who else is involved in evaluating solutions like this?" / "Walk me through your typical purchase process." |
| **Need** | Does the prospect have a genuine problem that your product solves? | "What prompted you to look into this?" / "What happens if this problem goes unsolved for another 6 months?" |
| **Timeline** | Is there a defined window for making a decision and implementing a solution? | "When are you looking to have a solution in place?" / "Is there a specific event driving the timeline?" |

### Scoring Rubric

| Score | Budget | Authority | Need | Timeline |
|-------|--------|-----------|------|----------|
| **5** | Explicit budget confirmed, within your price range | Final decision-maker with signing authority | Critical, urgent problem you solve directly | Decision within 30 days, implementation timeline set |
| **4** | Budget likely available, category spend confirmed | Strong influencer who owns the recommendation | Clear problem, actively seeking solutions | Decision within 60 days, general timeline in mind |
| **3** | Budget possible, no explicit confirmation | Mid-level with input but not final say | Recognized problem but not yet prioritized | Decision within 90 days, no specific urgency |
| **2** | Budget constrained signals, or unconfirmed | IC or early evaluator with limited influence | Vague awareness of problem, no active search | No timeline, "maybe next year" |
| **1** | Known budget constraints or misalignment | No buying authority, wrong department | No clear need, or need does not match product | No timeline, purely exploratory |

### Worked Example

**Prospect**: Sarah Chen, Director of Marketing at a 150-person SaaS company. Came in through a webinar registration. Company raised Series B 8 months ago.

- **Budget**: Series B funding suggests budget capacity. Director-level typically has $50K-100K discretionary spend. But no explicit budget mention. **Score: 3**
- **Authority**: Director of Marketing at 150-person company -- likely owns tool decisions for her team, but VP or CMO probably signs off on larger purchases. **Score: 4**
- **Need**: Registered for a product-category webinar, which implies awareness. But webinar attendance is low-intent. **Score: 3**
- **Timeline**: No timeline signals. Webinar attendees are often early-stage. **Score: 2**
- **BANT Average**: 3.0 -- Warm, needs discovery to confirm budget and timeline.

### Strengths
- Dead simple. Anyone can learn it in 5 minutes.
- Fast to apply. Works at volume.
- Universal vocabulary -- every sales team understands BANT.

### Weaknesses
- Surface-level. Tells you IF they can buy, not WHY they should buy from you.
- Budget-first ordering is outdated. Modern buyers often discover need before securing budget.
- Does not account for competitive dynamics, buying process complexity, or champion identification.
- Binary thinking. In practice, all four criteria exist on a spectrum.

### When to Use BANT
- Deal sizes under $25K ACV
- Sales cycles under 30 days
- High-volume qualification (qualifying 20+ leads per day)
- As a preliminary filter before deeper qualification with another framework

---

## MEDDICC: The Enterprise Standard

### Origin and Philosophy
Jack Napoli and Dick Dunkel developed MEDDIC at PTC in the 1990s, where it helped the company grow from $300M to $1B in revenue. The second "C" (Competition) was added later, creating MEDDICC. This framework treats each deal as a multi-stakeholder puzzle and systematically maps the political and procedural landscape.

### Criteria Definitions

| Criterion | What You Are Assessing | Key Questions |
|-----------|----------------------|---------------|
| **Metrics** | What quantifiable outcomes will the prospect use to measure success? | "What KPIs will you use to evaluate ROI?" / "What does success look like 6 months after deployment?" |
| **Economic Buyer** | Who has the final veto power and budget authority? | "Who signs the PO?" / "Who could kill this deal even if everyone else is on board?" |
| **Decision Criteria** | What specific requirements will drive the final decision? | "What are your must-haves vs. nice-to-haves?" / "How will you score the vendors?" |
| **Decision Process** | What steps, approvals, and timelines will the org follow? | "Walk me through your evaluation process from here to signed contract." |
| **Identify Pain** | What specific, quantifiable pain is driving the evaluation? | "What is this problem costing you today?" / "What triggered this search?" |
| **Champion** | Who inside the org will actively advocate for your solution? | "Who on your team is most affected by this problem?" / "Who would benefit most from solving this?" |
| **Competition** | Who else is being evaluated, and how do you compare? | "Who else are you looking at?" / "What criteria are you using to compare solutions?" |

### Scoring Rubric

| Score | What It Means |
|-------|--------------|
| **5** | Criterion fully validated with evidence. Metrics quantified. Champion confirmed and active. Economic buyer identified and engaged. |
| **4** | Criterion largely validated. Strong signals but not fully confirmed. Champion identified but not yet fully engaged. |
| **3** | Partial information. Some signals but significant gaps. Champion suspected but not confirmed. |
| **2** | Minimal information. Assumptions outweigh evidence. No clear champion yet. |
| **1** | No information or negative signals. Cannot identify key stakeholders. |

### Performance Data
- MEDDICC-trained teams see **12-15% higher win rates** on average (Gong, 2024 analysis of 2.5M deals)
- MEDDICC adoption correlates with **20% shorter sales cycles** for enterprise deals, primarily by identifying blockers earlier
- Organizations using MEDDICC report **35% more accurate forecasts** compared to BANT-only forecasting (Forrester, 2023)

### Strengths
- Extremely thorough. If you can fill out every MEDDICC field, you understand the deal deeply.
- Champion identification is uniquely valuable. No other common framework explicitly requires this.
- Competition criterion forces honest competitive assessment.
- Strong forecast predictor. Deals with 5+ MEDDICC criteria validated close at 3x the rate of those with 2 or fewer.

### Weaknesses
- Too heavy for first-pass qualification. You will not have MEDDICC answers on a first call.
- Requires significant seller skill. Junior reps often struggle to elicit this information naturally.
- Can feel like an interrogation if not woven into genuine conversation.
- Overkill for deals under $50K ACV.

### When to Use MEDDICC
- Enterprise deals above $50K ACV
- Sales cycles longer than 90 days
- Multi-stakeholder buying committees (3+ decision influencers)
- As a deepening framework AFTER initial qualification confirms the lead is worth pursuing
- Competitive deals where positioning matters

---

## ANUM: Authority-First Qualification

### Origin and Philosophy
ANUM (Authority, Need, Urgency, Money) flips BANT on its head by putting Authority first. The premise: if you are not talking to someone who can make or influence the decision, nothing else matters. Popularized by Ken Krogue of InsideSales.com.

### Criteria Definitions

| Criterion | What You Are Assessing |
|-----------|----------------------|
| **Authority** | Can this person make or directly influence the buying decision? |
| **Need** | Does the prospect have a real, recognized problem that your product addresses? |
| **Urgency** | Is there a time-sensitive driver compelling action? |
| **Money** | Can the prospect allocate budget for a solution in your price range? |

### When ANUM Beats BANT
- In organizations with strict hierarchical approval processes
- When your product is typically purchased by a specific executive level
- When you consistently lose deals because the champion cannot push it through
- In government and enterprise where authority gating is common

### Strengths
- Correctly prioritizes authority -- the most common reason deals stall
- "Urgency" is more actionable than "Timeline" (urgency implies a reason, timeline is just a date)
- Puts money last, recognizing that budget often follows established need and urgency

### Weaknesses
- Authority-first can lead to premature disqualification of valuable champions who lack title but have influence
- Does not account for decision process complexity
- No competitive or champion dimension

---

## CHAMP: Challenges-Led Qualification

### Origin and Philosophy
CHAMP (Challenges, Authority, Money, Prioritization) was developed by InsightSquared. It starts with the buyer's challenges -- not your solution -- and works outward. The philosophy: if you deeply understand the challenge, everything else (authority, budget, timing) becomes easier to navigate.

### Criteria Definitions

| Criterion | What You Are Assessing |
|-----------|----------------------|
| **Challenges** | What specific challenges is the prospect facing that your product can address? |
| **Authority** | Who owns these challenges, and who can authorize a solution? |
| **Money** | Is there budget allocated, or can budget be created based on challenge severity? |
| **Prioritization** | Where does solving this challenge rank among the prospect's other priorities? |

### When CHAMP Beats Other Frameworks
- Consultative or solution-selling motions
- When your product addresses multiple challenges and you need to identify the primary driver
- When buyers are early in their journey and do not yet know they need your category
- When you need to help the buyer build a business case internally

### Strengths
- Challenge-first approach naturally builds rapport (you are listening, not interrogating)
- "Prioritization" is more nuanced than "Timeline" -- a Q1 timeline means nothing if your project is priority #7
- Works well for creating urgency when none exists (by quantifying challenge impact)

### Weaknesses
- Can be slow. Deep challenge exploration takes time.
- Risk of "consulting syndrome" -- spending too much time understanding the problem and not enough qualifying the opportunity
- Less structured than MEDDICC for complex enterprise deals

---

## GPCTBA/C&I: The HubSpot Framework

### Origin and Philosophy
HubSpot developed GPCTBA/C&I (Goals, Plans, Challenges, Timeline, Budget, Authority, Consequences & Implications) as a comprehensive inbound qualification framework. It is designed for advisory selling where you help the buyer understand their own situation.

### Criteria Breakdown

| Layer | Criteria | Purpose |
|-------|----------|---------|
| **Strategic** | Goals, Plans, Challenges | Understand what the buyer is trying to achieve and what is in the way |
| **Operational** | Timeline, Budget, Authority | Determine practical feasibility of a purchase |
| **Impact** | Consequences & Implications | Quantify the cost of inaction and the value of action |

### The C&I Differentiator
The unique element is Consequences & Implications:
- **Consequences**: What happens if the prospect does NOT solve this problem? (negative framing)
- **Implications**: What becomes possible if the prospect DOES solve this problem? (positive framing)

This dual framing helps build urgency and a business case simultaneously.

### When to Use GPCTBA/C&I
- Inbound-heavy sales motions where leads have already self-educated
- Advisory or consultative selling where you are a trusted advisor, not just a vendor
- When you need to help the buyer build an internal business case
- Mid-market to enterprise deals with 2-4 stakeholders

### Strengths
- Most comprehensive framework available
- C&I layer creates urgency naturally by quantifying inaction
- Goal-first approach aligns your solution with the buyer's strategic objectives
- Works well with inbound methodology

### Weaknesses
- Seven criteria is a lot to track. Cognitive overhead is high.
- Too heavy for transactional sales or high-volume qualification
- Requires a sophisticated seller who can weave these questions into natural conversation

---

## The 5-Dimension Scoring Model

### Philosophy and Design
The 5-Dimension model is the default framework used in this skill. It was designed specifically for rapid first-pass qualification where data is often incomplete. Unlike BANT or MEDDICC, which assume you have access to the buyer for a conversation, the 5-Dimension model can be applied entirely from available data (CRM, web, LinkedIn) before any conversation occurs.

### Why These Five Dimensions

| Dimension | Weight | Why This Weight |
|-----------|--------|----------------|
| Company Size Fit | 25% | Strongest single predictor of ICP fit. Controls budget capacity, complexity requirements, and sales cycle length. |
| Industry Fit | 25% | Determines value proposition resonance and availability of proof points. Companies buy from vendors who understand their vertical. |
| Role Seniority & Authority | 20% | Controls whether this person can make or influence a buying decision. Slightly lower weight because authority can be navigated (find the right person). |
| Budget Signals | 15% | Important but usually indirect at first-pass. Rarely confirmed before a conversation. Weight reflects data availability. |
| Timing & Intent | 15% | Critical differentiator between "good fit" and "good fit right now." Lower weight because it is the most volatile dimension (can change overnight). |

### Compared to Other Frameworks

| Dimension | BANT Equivalent | MEDDICC Equivalent | What 5-Dimension Adds |
|-----------|----------------|-------------------|----------------------|
| Company Size Fit | (not explicit) | (not explicit) | Explicit ICP matching against firmographic data |
| Industry Fit | (not explicit) | (not explicit) | Proof point availability assessment |
| Role Seniority & Authority | Authority | Economic Buyer + Champion | Title-to-company-size calibration |
| Budget Signals | Budget | Metrics (indirect) | Proxy signal analysis (funding, hiring, tech spend) |
| Timing & Intent | Timeline | Identify Pain + Decision Process | Behavioral signal weighting over demographic signals |

### Source Quality Multiplier (Unique to 5-Dimension)
No other framework explicitly weights lead source. The 5-Dimension model applies a multiplier because source data is always available (unlike budget or timeline) and is independently predictive:

| Source | Multiplier | Data Source |
|--------|-----------|-------------|
| Customer referral | 1.25x | Referral leads convert at 4x the rate of cold inbound (Salesforce, State of Sales 2024) |
| Partner referral | 1.15x | Partner referrals convert at 2.5x cold inbound |
| Demo request | 1.15x | Direct demo requests indicate explicit high intent |
| Content inbound | 1.0x | Baseline |
| Event lead | 1.0x | Mixed signal, highly variable |
| Cold outbound | 0.9x | Lower initial intent, requires more nurturing |
| Purchased list | 0.8x | Lowest quality, highest data accuracy issues |

---

## Framework Selection Decision Tree

Use this decision tree to select the right framework based on your deal context:

```
START: What is the estimated ACV?
  |
  |-- Under $10K ACV
  |     --> BANT or 5-Dimension (speed matters, qualify at volume)
  |
  |-- $10K-$50K ACV
  |     |
  |     |-- Sales cycle < 60 days?
  |     |     --> BANT for first pass, CHAMP for discovery
  |     |
  |     |-- Sales cycle 60-120 days?
  |           --> 5-Dimension for first pass, ANUM or CHAMP for discovery
  |
  |-- $50K-$200K ACV
  |     |
  |     |-- Single decision-maker?
  |     |     --> ANUM for first pass, CHAMP for discovery
  |     |
  |     |-- Multi-stakeholder (3+)?
  |           --> 5-Dimension for first pass, MEDDICC for deal progression
  |
  |-- Over $200K ACV
        --> 5-Dimension for first pass, MEDDICC mandatory for deal progression
```

### Framework Stacking
In practice, top-performing teams do not use a single framework. They stack:

1. **First Pass (inbound arrival)**: 5-Dimension scoring to assign tier and priority
2. **Discovery Call**: BANT (simple deals) or CHAMP (complex deals) to validate assumptions
3. **Deal Progression**: MEDDICC (enterprise) or GPCTBA/C&I (mid-market) to track deal health
4. **Competitive Deals**: MEDDICC's Competition criterion supplemented by the competitor-intel skill

---

## Conversion Rate Data by Framework

### Industry Benchmarks

| Framework | Avg Win Rate (trained teams) | Avg Win Rate (untrained) | Lift | Source |
|-----------|------------------------------|--------------------------|------|--------|
| BANT | 22% | 18% | +22% | CSO Insights, 2023 |
| MEDDICC | 28% | 16% | +75% | Gong, 2024 (2.5M deals analyzed) |
| ANUM | 24% | 19% | +26% | InsideSales.com, 2022 |
| CHAMP | 25% | 18% | +39% | InsightSquared, 2023 |
| GPCTBA/C&I | 27% | 20% | +35% | HubSpot Research, 2023 |

### The Consistency Effect
The biggest lift from any framework comes not from which framework you choose, but from using one consistently. Teams that apply any structured qualification framework consistently outperform teams that "wing it" by 40-60% (Forrester, B2B Sales Survey 2024).

### Framework Adoption Correlation with Deal Velocity
- MEDDICC: 20% shorter sales cycles for enterprise (by identifying blockers earlier)
- BANT: 15% shorter cycles for SMB (by disqualifying faster)
- CHAMP: 10% shorter cycles for mid-market (by aligning on priority faster)

---

## Scoring Rubric Worked Examples

### Example 1: Strong Inbound Lead (SaaS Mid-Market)

**Context**: Maria Torres, VP of Sales at CloudOps (280 employees, Series B, DevOps SaaS). Requested a demo after downloading a case study. Found via Google search for "[your product category] for DevOps teams."

**5-Dimension Scoring**:

| Dimension | Score | Weight | Weighted | Reasoning |
|-----------|-------|--------|----------|-----------|
| Company Size | 5 | 25% | 1.25 | 280 employees -- squarely in ICP sweet spot of 100-500 |
| Industry Fit | 5 | 25% | 1.25 | DevOps SaaS -- target vertical with 3 existing case studies |
| Role Authority | 5 | 20% | 1.00 | VP of Sales at 280-person company = clear decision-maker |
| Budget Signals | 4 | 15% | 0.60 | Series B = strong budget signal, but no explicit budget confirmation |
| Timing & Intent | 5 | 15% | 0.75 | Demo request + case study download + active Google search = strong intent |

**Raw Score**: 4.85
**Source Multiplier**: Demo request = 1.15x
**Final Score**: 5.0 (capped)
**Tier**: HOT
**Confidence**: High (4+ data points per dimension)

### Example 2: Weak Inbound Lead (Borderline)

**Context**: Jake Nguyen, Marketing Coordinator at FreshBites (12 employees, food delivery startup, no known funding). Signed up for newsletter after blog post.

**5-Dimension Scoring**:

| Dimension | Score | Weight | Weighted | Reasoning |
|-----------|-------|--------|----------|-----------|
| Company Size | 1 | 25% | 0.25 | 12 employees -- far below ICP minimum of 50 |
| Industry Fit | 2 | 25% | 0.50 | Food delivery -- not target vertical, no case studies, but not inherently disqualifying |
| Role Authority | 1 | 20% | 0.20 | Marketing Coordinator at 12-person startup = IC with no buying authority |
| Budget Signals | 1 | 15% | 0.15 | No funding data, micro-startup, likely bootstrap budget |
| Timing & Intent | 2 | 15% | 0.30 | Newsletter signup = awareness only, no product intent |

**Raw Score**: 1.40
**Source Multiplier**: Content inbound = 1.0x
**Final Score**: 1.40
**Tier**: DISQUALIFIED
**Confidence**: Medium (2-3 data points per dimension)
**Reason**: Below minimum company size, no buying authority, no intent signals.

### Example 3: Data-Sparse Lead (Low Confidence)

**Context**: Alex Kim, unknown title, at TechVenture (unknown size). Email only: alex@techventure.io. Source: outbound cold list.

**5-Dimension Scoring**:

| Dimension | Score | Weight | Weighted | Reasoning |
|-----------|-------|--------|----------|-----------|
| Company Size | 0 | 25% | 0.00 | Cannot determine -- no data |
| Industry Fit | 0 | 25% | 0.00 | Cannot determine -- no data |
| Role Authority | 0 | 20% | 0.00 | Cannot determine -- no title |
| Budget Signals | 0 | 15% | 0.00 | Cannot determine -- no data |
| Timing & Intent | 1 | 15% | 0.15 | Cold list = lowest intent signal |

**Raw Score**: 0.15
**Source Multiplier**: Purchased list = 0.8x
**Final Score**: 0.12
**Tier**: DISQUALIFIED (pending enrichment)
**Confidence**: LOW
**Next Action**: Run lead-research skill to enrich before scoring. Score is not meaningful with current data.

---

## Framework Migration Guide

### Migrating from BANT to 5-Dimension

If your team currently uses BANT and you are transitioning to the 5-Dimension model:

| BANT Criterion | Maps To | What Changes |
|----------------|---------|-------------|
| Budget | Budget Signals (15%) | Weight decreases. Proxy signals replace explicit budget confirmation. |
| Authority | Role Seniority & Authority (20%) | Enhanced with title-to-company-size calibration. |
| Need | Industry Fit (25%) + Timing & Intent (15%) | Splits into "is there a structural fit?" and "is there active intent?" |
| Timeline | Timing & Intent (15%) | Behavioral signals weighted more heavily than stated timeline. |
| (none) | Company Size Fit (25%) | NEW: Explicit ICP matching on firmographics. |
| (none) | Source Multiplier | NEW: Lead source weighting applied to final score. |

### Migrating from 5-Dimension to MEDDICC (Deal Progression)

When a lead is qualified as Hot or Warm via 5-Dimension and enters the pipeline, transition to MEDDICC for deal tracking:

| 5-Dimension Data | Seeds This MEDDICC Field |
|-----------------|------------------------|
| Company Size + Industry Fit | Helps define Metrics (what success looks like for this company size/vertical) |
| Role Authority score | Seeds Economic Buyer identification |
| Budget Signals | Informs early Metrics conversation (expected ROI) |
| Timing & Intent | Seeds Identify Pain (what drove the evaluation) |
| CRM relationship data | Seeds Champion identification |
| Source quality | Informs Decision Process assumptions |

---

## Sources and Further Reading

- Gong Research Labs. "The Impact of Sales Methodologies on Win Rates." 2024. Analysis of 2.5M B2B sales deals.
- Forrester Research. "B2B Buyer Journey Survey." 2024. Survey of 1,200 B2B buyers.
- CSO Insights. "Sales Performance Optimization Study." 2023.
- InsightSquared. "CHAMP Framework White Paper." 2023.
- HubSpot Research. "State of Inbound Sales." 2023.
- Salesforce. "State of Sales Report." 5th Edition, 2024.
- Jack Napoli. "MEDDIC: The Ultimate Guide to Staying One Step Ahead in the Complex Sale." 2022.
- Force Management. "Command of the Message and MEDDICC." Training materials.
- Harvard Business Review. "The Short Life of Online Sales Leads." James B. Oldroyd, Kristina McElheran, David Elkington.
